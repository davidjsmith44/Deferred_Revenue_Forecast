{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deferred Revenue Forecast\n",
    "\n",
    "This jupyter notebook contains the details Adobe's deferred revenue forecast model in a more readable, easy to understand format.\n",
    "\n",
    "The program is run from python directly (versus using a notebook like we have here) and the details are available on my github page www.github.com/davidjsmith44/Deferred_Revenue_Forecast\n",
    "Note: You will need me to give you access to this repository as it is not public\n",
    "\n",
    "<b>This is bold text </b>\n",
    "\n",
    "<i>Italic Text </i>\n",
    "\n",
    "<blockquote> This is where I have my blockquote text. It will all be indented to make it easier to read </blockquote>\n",
    "\n",
    "This is not blockquote, but below is a horizontal line\n",
    "___\n",
    "\n",
    "<b> Step 1: Process the Base Billings Data </B>\n",
    "\n",
    "\n",
    "Steps to the program\n",
    "1. Load up all input data\n",
    "    - billings history\n",
    "        - Type A\n",
    "    - FX rates\n",
    "    - FX_currency map\n",
    "    - FX forwards\n",
    "    - bookings data\n",
    " \n",
    " \n",
    " 2. Process the billings data into a dataframe that includes the BU, currency, period and every type of billings based on it's rebill frequency\n",
    " \n",
    " 3. Process the bookings information\n",
    "\n",
    "4. Forecast the future billings\n",
    "\n",
    "5. Basic reporting documents\n",
    "\n",
    "6. Checking for sanity\n",
    "\n",
    "\n",
    "NOTE: If you plan on using a Jupyter Notebook to run the Deferred Revenue Forecast, you must first download all of the input data to your local directory. I do not yet know how to use a Jupyter Notebook and access data off of the Treasury server.\n",
    "\n",
    "The input data sits on the Treasury server under Treasury\\Financial_Database\\Deferred_Revenue\\Inputs\\Data_YYYY_pMM\n",
    "\n",
    "There will be 6 files located at this directory that need to be copied to your local drive (preferably where you have installed Anaconda) under a directory called data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Begins here\n",
    "Below are standard import statements to include all the functionality of numpy, pandas, matplotlib, pickle and a linear regression moodel from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from math import ceil\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Processing Base Billings Data\n",
    "\n",
    "The billings data comes from tableau and is saved in a file \"all_billings_inputs.xlsx\" with two sheets of information\n",
    "\n",
    "\"base_billings\"\n",
    "Contains the basic information about all of the billings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/all_billings_inputs.xlsx', sheet_name='base_billings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Currency</th>\n",
       "      <th>Enterprise BU Desc</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Invoice Fiscal Year Period Desc</th>\n",
       "      <th>Product Config Type</th>\n",
       "      <th>Rev Rec Category</th>\n",
       "      <th>Rule For Bill Date</th>\n",
       "      <th>Sales Type</th>\n",
       "      <th>Subscription Term</th>\n",
       "      <th>Completed Sales ( DC )</th>\n",
       "      <th>Completed Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36629</th>\n",
       "      <td>SEK</td>\n",
       "      <td>Print &amp; Publishing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>1V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECOGNIZED</td>\n",
       "      <td>0</td>\n",
       "      <td>3420.00</td>\n",
       "      <td>400.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24279</th>\n",
       "      <td>GBP</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>ONGO</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31136</th>\n",
       "      <td>JPY</td>\n",
       "      <td>Print &amp; Publishing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>822216.00</td>\n",
       "      <td>7297.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30453</th>\n",
       "      <td>JPY</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>ONGO</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECOGNIZED</td>\n",
       "      <td>0</td>\n",
       "      <td>9306650.00</td>\n",
       "      <td>82895.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44828</th>\n",
       "      <td>USD</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>ACTL</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>YC</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>70000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41840</th>\n",
       "      <td>USD</td>\n",
       "      <td>Document Cloud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>12</td>\n",
       "      <td>4027054.29</td>\n",
       "      <td>4027054.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17127</th>\n",
       "      <td>EUR</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>ONGO</td>\n",
       "      <td>2015-08</td>\n",
       "      <td>ONORE</td>\n",
       "      <td>D</td>\n",
       "      <td>YH</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>127112.65</td>\n",
       "      <td>140958.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26830</th>\n",
       "      <td>JPY</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>IDRT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECOGNIZED</td>\n",
       "      <td>0</td>\n",
       "      <td>74080.00</td>\n",
       "      <td>606.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31097</th>\n",
       "      <td>JPY</td>\n",
       "      <td>Print &amp; Publishing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>1V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECOGNIZED</td>\n",
       "      <td>0</td>\n",
       "      <td>215282.00</td>\n",
       "      <td>1916.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16163</th>\n",
       "      <td>EUR</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>1TME</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>YQ</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>362.48</td>\n",
       "      <td>428.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document Currency  Enterprise BU Desc Frequency  \\\n",
       "36629               SEK  Print & Publishing       NaN   \n",
       "24279               GBP    Experience Cloud      ONGO   \n",
       "31136               JPY  Print & Publishing       NaN   \n",
       "30453               JPY    Experience Cloud      ONGO   \n",
       "44828               USD    Experience Cloud      ACTL   \n",
       "41840               USD      Document Cloud       NaN   \n",
       "17127               EUR    Experience Cloud      ONGO   \n",
       "26830               JPY            Creative       NaN   \n",
       "31097               JPY  Print & Publishing       NaN   \n",
       "16163               EUR    Experience Cloud      1TME   \n",
       "\n",
       "      Invoice Fiscal Year Period Desc Product Config Type Rev Rec Category  \\\n",
       "36629                         2015-05                  1V              NaN   \n",
       "24279                         2018-07                 NaN              NaN   \n",
       "31136                         2017-08                  1Y                D   \n",
       "30453                         2018-10                 NaN              NaN   \n",
       "44828                         2016-07                 NaN                D   \n",
       "41840                         2020-04                  1Y                D   \n",
       "17127                         2015-08               ONORE                D   \n",
       "26830                         2016-01                IDRT              NaN   \n",
       "31097                         2017-04                  1V              NaN   \n",
       "16163                         2017-09                 NaN                D   \n",
       "\n",
       "      Rule For Bill Date  Sales Type  Subscription Term  \\\n",
       "36629                NaN  RECOGNIZED                  0   \n",
       "24279                NaN    DEFERRED                  0   \n",
       "31136                 Y3    DEFERRED                  1   \n",
       "30453                NaN  RECOGNIZED                  0   \n",
       "44828                 YC    DEFERRED                  0   \n",
       "41840                NaN    DEFERRED                 12   \n",
       "17127                 YH    DEFERRED                  0   \n",
       "26830                NaN  RECOGNIZED                  0   \n",
       "31097                NaN  RECOGNIZED                  0   \n",
       "16163                 YQ    DEFERRED                  0   \n",
       "\n",
       "       Completed Sales ( DC )  Completed Sales  \n",
       "36629                 3420.00           400.48  \n",
       "24279                    0.00             0.00  \n",
       "31136               822216.00          7297.97  \n",
       "30453              9306650.00         82895.26  \n",
       "44828                70000.00         70000.00  \n",
       "41840              4027054.29       4027054.29  \n",
       "17127               127112.65        140958.44  \n",
       "26830                74080.00           606.71  \n",
       "31097               215282.00          1916.96  \n",
       "16163                  362.48           428.51  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the column names early since they are inconsistent across other reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index = str, columns = {'Document Currency': 'curr',\n",
    "                                 'Enterprise BU Desc': 'BU',\n",
    "                                 'Invoice Fiscal Year Period Desc': 'period',\n",
    "                                 'Product Config Type': 'config',\n",
    "                                 'Rev Rec Category': 'rev_req_type',\n",
    "                                 'Rule For Bill Date': 'rebill_rule',\n",
    "                                 'Completed Sales ( DC )': 'DC_amount',\n",
    "                                 'Completed Sales': 'US_amount'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter that removes any currency that has  < 10 transactions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD    12427\n",
      "EUR     7725\n",
      "GBP     5714\n",
      "AUD     5068\n",
      "JPY     4919\n",
      "CHF     2389\n",
      "SEK     2260\n",
      "DKK     2172\n",
      "NOK     1854\n",
      "CAD     1520\n",
      "HKD      486\n",
      "BRL      466\n",
      "RUB      461\n",
      "KRW      247\n",
      "CLP      211\n",
      "ARS      210\n",
      "COP      210\n",
      "SGD      209\n",
      "PEN      190\n",
      "INR      181\n",
      "PHP      151\n",
      "TWD      148\n",
      "THB      144\n",
      "MYR      138\n",
      "IDR      132\n",
      "NZD       67\n",
      "ILS       38\n",
      "TRY       27\n",
      "SAR        4\n",
      "BMD        2\n",
      "AED        1\n",
      "MXP        1\n",
      "Name: curr, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# creates a list of the currencies and the number of transactions for each currency\n",
    "vc = df['curr'].value_counts()\n",
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable that is true if the number of transaction is greater than 10, false otherwise\n",
    "keep_these = vc.values > 10\n",
    "# filtering only currencies that were greater than 10\n",
    "keep_curr = vc[keep_these]\n",
    "a = keep_curr.index\n",
    "# filtering the dataframe to remove any of teh currencies not in our list\n",
    "df = df[df['curr'].isin(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just keeping track of the currencies we removed in our model_dict data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_these = vc[vc.values <= 10].index\n",
    "model_dict = {'curr_removed': list(vc[remove_these].index)}\n",
    "delete_curr = list(remove_these)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The FX database does not have information on the following currencies\n",
    " - AED (United Arab Emirates Dirham)\n",
    " - BMD (Bermudan Dollar)\n",
    " - MXP (Mexican Peso)\n",
    " - TRY (Turkish Lira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dictionary {'curr_removed': ['SAR', 'BMD', 'AED', 'MXP', 'TRY']}\n",
      "Deleted Currencies ['SAR', 'BMD', 'AED', 'MXP', 'TRY']\n"
     ]
    }
   ],
   "source": [
    "if 'TRY' not in model_dict:\n",
    "    model_dict['curr_removed'].append('TRY')\n",
    "    delete_curr.append('TRY')\n",
    "    a = a.drop('TRY')\n",
    "    \n",
    "print('Model dictionary', model_dict)\n",
    "print('Deleted Currencies', delete_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Removing infrequent currencies from billings history---\n",
      "Total number of currencies in the base billings file:  32\n",
      "\n",
      " Currencies were removed:  5\n",
      "SAR , BMD , AED , MXP , \n",
      "\n",
      "27 Remaining currencies: \n",
      "USD , EUR , GBP , AUD , JPY , CHF , SEK , DKK , NOK , CAD , HKD , BRL , RUB , KRW , CLP , ARS , COP , SGD , PEN , INR , PHP , TWD , THB , MYR , IDR , NZD , ILS , "
     ]
    }
   ],
   "source": [
    "print(\"---Removing infrequent currencies from billings history---\")\n",
    "print('Total number of currencies in the base billings file: ', len(vc))\n",
    "if len(model_dict['curr_removed'])==0:\n",
    "    print('No currencies were removed, all contained 10 or more billings')\n",
    "    print('Currencies in the base billings file')\n",
    "    for item in a:\n",
    "        print(a[item], end = \" \")\n",
    "else:\n",
    "    print('\\n Currencies were removed: ', len(model_dict['curr_removed']))\n",
    "\n",
    "    for item in remove_these:\n",
    "        print(item, ', ', end=\"\")\n",
    "        \n",
    "    print(\"\\n\\n{} Remaining currencies: \".format(len(a)))\n",
    "    for item in a:\n",
    "        print(item, ', ', end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing any of the values that are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the length of the dataframe before removing zeros:  49764\n",
      "This is the length of the dataframe after removing zeros:  46285\n"
     ]
    }
   ],
   "source": [
    "print('This is the length of the dataframe before removing zeros: ', len(df))\n",
    "df = df[df['DC_amount']!=0]\n",
    "print('This is the length of the dataframe after removing zeros: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr</th>\n",
       "      <th>BU</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>period</th>\n",
       "      <th>config</th>\n",
       "      <th>rev_req_type</th>\n",
       "      <th>rebill_rule</th>\n",
       "      <th>Sales Type</th>\n",
       "      <th>Subscription Term</th>\n",
       "      <th>DC_amount</th>\n",
       "      <th>US_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>-11291.52</td>\n",
       "      <td>-289.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>373766.00</td>\n",
       "      <td>9601.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>YA</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>12</td>\n",
       "      <td>241380.00</td>\n",
       "      <td>6194.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>MTHLY</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>-1221.00</td>\n",
       "      <td>-31.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>MTHLY</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>45799.00</td>\n",
       "      <td>1173.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>-40014.70</td>\n",
       "      <td>-985.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>1705471.00</td>\n",
       "      <td>42032.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>YA</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>12</td>\n",
       "      <td>1112854.12</td>\n",
       "      <td>27486.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>MTHLY</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>-14292.80</td>\n",
       "      <td>-351.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARS</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>MTHLY</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>188938.00</td>\n",
       "      <td>4653.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   curr        BU Frequency   period config rev_req_type rebill_rule  \\\n",
       "1   ARS  Creative       NaN  2019-03     1Y            D         NaN   \n",
       "2   ARS  Creative       NaN  2019-03     1Y            D          Y3   \n",
       "3   ARS  Creative       NaN  2019-03     1Y            D          YA   \n",
       "4   ARS  Creative       NaN  2019-03  MTHLY            D         NaN   \n",
       "5   ARS  Creative       NaN  2019-03  MTHLY            D          Y3   \n",
       "6   ARS  Creative       NaN  2019-04     1Y            D         NaN   \n",
       "7   ARS  Creative       NaN  2019-04     1Y            D          Y3   \n",
       "8   ARS  Creative       NaN  2019-04     1Y            D          YA   \n",
       "9   ARS  Creative       NaN  2019-04  MTHLY            D         NaN   \n",
       "10  ARS  Creative       NaN  2019-04  MTHLY            D          Y3   \n",
       "\n",
       "   Sales Type  Subscription Term   DC_amount  US_amount  \n",
       "1    DEFERRED                  1   -11291.52    -289.26  \n",
       "2    DEFERRED                  1   373766.00    9601.19  \n",
       "3    DEFERRED                 12   241380.00    6194.45  \n",
       "4    DEFERRED                  1    -1221.00     -31.07  \n",
       "5    DEFERRED                  1    45799.00    1173.37  \n",
       "6    DEFERRED                  1   -40014.70    -985.24  \n",
       "7    DEFERRED                  1  1705471.00   42032.83  \n",
       "8    DEFERRED                 12  1112854.12   27486.58  \n",
       "9    DEFERRED                  1   -14292.80    -351.04  \n",
       "10   DEFERRED                  1   188938.00    4653.43  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearing out the Non-Revenue billings from the file\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEFERRED       37628\n",
       "RECOGNIZED      7183\n",
       "PRO-SVC-INV     1323\n",
       "NON-REV          150\n",
       "Name: Sales Type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sales Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataframe before removing non-revenue billings:  46285\n",
      "Length of the dataframe after removing non-revenue billings:   46135\n"
     ]
    }
   ],
   "source": [
    "print('Length of the dataframe before removing non-revenue billings: ', len(df))\n",
    "df = df[df['Sales Type']!='NON-REV']\n",
    "print('Length of the dataframe after removing non-revenue billings:  ', len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Starting to group the revenue by period, industry, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the data by the <b> Sales Type </b> field\n",
    " - <i>'RECOGNIZED'</i> sales are perpetual and go straight to revenue without hitting deferred \n",
    " - <i>'PRO-SVC-INV'</i> professional services that are invoiced and go to revenue directly when invoiced\n",
    " - <i>'DEFERRED'</i> sales that will sit on the balance sheet in deferred revenue and amortize over their life\n",
    " \n",
    " #### Below we are creating a seperate dataframe for each of the Sales Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of billings:               46135\n",
      "Number of recognized revenue billings:  7183\n",
      "Number of service invoiced billings:    1323\n",
      "Number of deferred revenue billings:    37628\n"
     ]
    }
   ],
   "source": [
    "rec = df[df['Sales Type']=='RECOGNIZED'].copy()\n",
    "svc = df[df['Sales Type']=='PRO-SVC-INV'].copy()\n",
    "dfr = df[df['Sales Type']=='DEFERRED'].copy()\n",
    "\n",
    "print('Total number of billings:              ', len(df))\n",
    "print(\"Number of recognized revenue billings: \", len(rec))\n",
    "print(\"Number of service invoiced billings:   \", len(svc))\n",
    "print(\"Number of deferred revenue billings:   \", len(dfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognized Revenue\n",
    "\n",
    "The rec.head(5) command will show the first 5 elements of the rec dataframe. To run this, simply remove the # before this line\n",
    " \n",
    "The rec.tail(5) command will show the last 5 elements of the rec dataframe. To run this, simply remove the # before this line\n",
    "\n",
    "The rec.sample(5) command will show the a random 5 elements of the rec dataframe. To run this, simply remove the # before this line\n",
    "\n",
    "Note: Only one of these commands can be entered in a single code cell at a time. \n",
    "\n",
    "Note: The 5 can also be changed, but I think it caps out at 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rec.head(5)\n",
    "#rec.tail(5)\n",
    "#rec.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below we are grouping the rec dataframe by currency, Business Unit and Period and cleaning up the data we do not need. Since the recognized revenue go directly to revenue, there is no contract that will renew and need to be modeled in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing groupby object\n",
    "gb_rec = rec.groupby(['curr', 'BU', 'period'], as_index=False).sum()\n",
    "gb_rec.drop(labels='Subscription Term', axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_rec.head(10)\n",
    "#gb_rec.tail(10)\n",
    "#gb_rec.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3347 entries, 0 to 3346\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   curr       3347 non-null   object \n",
      " 1   BU         3347 non-null   object \n",
      " 2   period     3347 non-null   object \n",
      " 3   DC_amount  3347 non-null   float64\n",
      " 4   US_amount  3347 non-null   float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 156.9+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Billings\n",
    "\n",
    "##### Below we are grouping the svc dataframe by currency, Business Unit and Period and cleaning up the data we do not need. Since the service billings go directly to revenue, there is no contract that will renew and need to be modeled in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_svc = svc.groupby(['curr', 'BU', 'period'], as_index=False).sum()\n",
    "gb_svc.drop(labels='Subscription Term', axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_svc.head(5)\n",
    "#gb_svc.tail(5)\n",
    "#gb_svc.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFERRED BILLINGS\n",
    "\n",
    "#### Type B Billings \n",
    "Type B billings are service agreements that will have invoices submitted before the billings are reclassified to revenue. If no invoices are assigned to the billings, the billings become revenue in 12 months. Since these billings do not have a contract that will renew in the future, there is no need to model a rebillings of these service based billings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_b = dfr[dfr['rev_req_type']=='B'].copy()\n",
    "gb_b = dfr_b.groupby(['curr', 'BU', 'period'], as_index=False).sum()\n",
    "gb_b.drop(labels='Subscription Term', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_b.drop(labels='Subscription Term', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Type A Billings\n",
    "These billings are on a billing plan. The product config tells us how long before they renew\n",
    "\n",
    " - '3Y' = 36 months\n",
    " - '2Y' = 24 months\n",
    " - '1Y' = 12 months\n",
    " - 'MTHLY' = 1 month\n",
    " \n",
    "NOTE: There are also other fields in the 'Product Configtype ID' field that do not map well to a rebill period.\n",
    "To fix this, we need to load up a different file and determine the length of the sales contract (type A no config)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering just the type A billings\n",
    "dfr_a = dfr[dfr['rev_req_type']=='A'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a = dfr_a.groupby(['curr', 'BU', 'period',\n",
    "                     'config'], as_index=False).sum()\n",
    "gb_a.drop(labels='Subscription Term', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a['config'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is just a check to see how large the billing types are across all periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a_config = gb_a.groupby(['config'], as_index=False).sum()\n",
    "gb_a_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These 'OCONS', 'ONORE' and 'OUNIV' data types are not actual product config IDs so we have to get them from a different data file. We are excluding these types below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = ['1Y', '2Y', '3Y', 'MTHLY']\n",
    "test1 = gb_a[gb_a['config'].isin(config_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For now, lets just split this into gb_a_1Y, gb_a_2Y, gb_a_3y, gb_a_1M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a_1Y = test1[test1['config']=='1Y'].copy()\n",
    "gb_a_2Y = test1[test1['config']=='2Y'].copy()\n",
    "gb_a_3Y = test1[test1['config']=='3Y'].copy()\n",
    "gb_a_1M = test1[test1['config']=='MTHLY'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('this is the lenght of type A 1M billings: ', len(gb_a_1M))\n",
    "print('this is the lenght of type A 1Y billings: ', len(gb_a_1Y))\n",
    "print('this is the lenght of type A 2Y billings: ', len(gb_a_2Y))\n",
    "print('this is the lenght of type A 3Y billings: ', len(gb_a_3Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a_2Y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TYPE D billings\n",
    "These billings have a field 'Rule For Bill Date' that determines when new billings will occur\n",
    " - Monthly:        *{Y1, Y2, Y3, Y5}*\n",
    " - Quarterly:      *YQ*\n",
    " - Every 4 months: *YT*  --NOTE: There are only 10 of these, so I am treating these as quarterly--\n",
    " - Semi-annual:    *YH*\n",
    " - Annual:         *{YA, YC}*\n",
    " - Every 2 years:  *Y4*\n",
    " - Every 3 years:  *Y7*\n",
    " \n",
    " We also need to track the type D billings that do not have a 'Rule for Bill Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now just do a groupby on the type\n",
    "# filtering just the type A billings\n",
    "dfr_d = dfr[dfr['rev_req_type']=='D'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_d = dfr_d.groupby(['curr', 'BU', 'period',\n",
    "                     'rebill_rule'], as_index=False).sum()\n",
    "gb_d.drop(labels='Subscription Term', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_d['rebill_rule'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_d_mthly = gb_d[gb_d['rebill_rule'].isin(['Y1', 'Y2', 'Y3', 'YM'])].copy()\n",
    "gb_d_mthly.drop(labels='rebill_rule', axis=1,inplace=True)\n",
    "gb_d_mthly = gb_d_mthly.groupby(['curr', 'BU', 'period']).sum()\n",
    "gb_d_mthly.reset_index(inplace=True)\n",
    "\n",
    "gb_d_qtrly = gb_d[gb_d['rebill_rule'].isin(['YQ', 'YY', 'YT'])].copy()\n",
    "gb_d_qtrly.drop(labels='rebill_rule', axis=1,inplace=True)\n",
    "gb_d_qtrly = gb_d_qtrly.groupby(['curr', 'BU', 'period']).sum()\n",
    "gb_d_qtrly.reset_index(inplace=True)\n",
    "\n",
    "gb_d_semi_ann = gb_d[gb_d['rebill_rule']=='YH']\n",
    "\n",
    "gb_d_annual = gb_d[gb_d['rebill_rule'].isin(['YA', 'YC', 'YX'])].copy()\n",
    "gb_d_annual.drop(labels='rebill_rule', axis=1,inplace=True)\n",
    "gb_d_annual = gb_d_annual.groupby(['curr', 'BU', 'period']).sum()\n",
    "gb_d_annual.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "gb_d_two_yrs = gb_d[gb_d['rebill_rule']=='Y4']\n",
    "gb_d_three_yrs = gb_d[gb_d['rebill_rule']=='Y7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_d_annual.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of monthly', len(gb_d_mthly))\n",
    "print('Length of quarterly', len(gb_d_qtrly))\n",
    "print('Length of four months', len(gb_d_four_mths))\n",
    "print('Length of semi ann', len(gb_d_semi_ann))\n",
    "print('Length of annual', len(gb_d_annual))\n",
    "print('Length of two years', len(gb_d_two_yrs))\n",
    "print('Length of three years', len(gb_d_three_yrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW WE NEED TO BUILD A DATAFRAME THAT INTEGRATES THIS DATA\n",
    "\n",
    "- We will have the following descriptive fields\n",
    "   - Invoicing Fiscal Year-Period\n",
    "   - Document Currency\n",
    "   - Enterprise BU\n",
    "\n",
    "- We will have the following fields based on rebilling rule\n",
    "   - Recognized\n",
    "   - Service\n",
    "   - Monthly\n",
    "   - Quarterly\n",
    "   - Annual\n",
    "   - Two Years\n",
    "   - Three Years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do it this way when we get to a .py file!\n",
    "list_df = [gb_rec, gb_svc, gb_b,\n",
    "        gb_a_1M,    gb_a_1Y,    gb_a_2Y,       gb_a_3Y, \n",
    "        gb_d_mthly, gb_d_qtrly, gb_d_semi_ann, gb_d_annual, gb_d_two_yrs, gb_d_three_yrs]\n",
    "\n",
    "list_columns = ['recognized', 'service', 'deferred_B', \n",
    "    'deferred_1M_a', 'deferred_1Y_a', 'deferred_2Y_a', 'deferred_3Y_a',\n",
    "    'deferred_1M_d', 'deferred_3M_d', 'deferred_6M_d', 'deferred_1Y_d', 'deferred_2Y_d', 'deferred_3Y_d']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_USD_amt(list_df, list_columns):\n",
    "    total_US = []\n",
    "    for df in list_df:\n",
    "        total_US.append(df['US_amount'].sum())\n",
    "    total_df = pd.DataFrame(index = list_columns, columns = ['US_amounts'], data=total_US)\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_dataframes(list_df, list_columns):\n",
    "    for i, df in enumerate(list_df):\n",
    "        print('This is i:', i)\n",
    "        #print(\"This is the df: \", df.head())\n",
    "        print('referencing the column: ', list_columns[i])\n",
    "\n",
    "        if i==0:\n",
    "            df_merged = list_df[0].copy()\n",
    "            df_merged.rename(index=str, columns={'DC_amount': list_columns[i]+'_DC', \n",
    "                                                 'US_amount': list_columns[i]+'_US'}, inplace=True)\n",
    "        else:\n",
    "            df_merged = merge_new_dataframe(df_merged, df, list_columns[i])\n",
    "\n",
    "    return df_merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_new_dataframe(old_df, new_df, new_column):\n",
    "    df_merged = pd.merge(old_df, new_df, how='outer', \n",
    "                     left_on=['curr', 'BU', 'period'],\n",
    "                    right_on=['curr', 'BU', 'period'])\n",
    "    df_merged.rename(index=str, columns={'DC_amount': new_column+'_DC', 'US_amount': new_column+'_US'}, inplace=True)\n",
    "    \n",
    "    #need to drop the product configtype id for merges where the new_df is of type A\n",
    "    config_str = 'config'\n",
    "    rule_str = 'rebill_rule'\n",
    "    if config_str in df_merged.columns:\n",
    "        df_merged.drop(columns=['config'], inplace=True)\n",
    "    \n",
    "    if rule_str in df_merged.columns:\n",
    "        df_merged.drop(columns=['rebill_rule'], inplace=True)\n",
    "        \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_all_dataframes(list_df, list_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_columns(df):\n",
    "    \n",
    "    # clean up NaNs before adding \n",
    "    df = df.fillna(value=0)\n",
    "    \n",
    "    # DC columns first\n",
    "    # Monthly\n",
    "    df['deferred_1M_DC'] = df['deferred_1M_a_DC']+df['deferred_1M_d_DC']\n",
    "    df.drop(labels=['deferred_1M_a_DC', 'deferred_1M_d_DC'], axis=1, inplace=True)\n",
    "    \n",
    "    # Annual\n",
    "    df['deferred_1Y_DC'] = df['deferred_1Y_a_DC']+df['deferred_1Y_d_DC']\n",
    "    df.drop(labels=['deferred_1Y_a_DC', 'deferred_1Y_d_DC'], axis=1, inplace=True)\n",
    "    \n",
    "    # Two-Year\n",
    "    df['deferred_2Y_DC'] = df['deferred_2Y_a_DC']+df['deferred_2Y_d_DC']\n",
    "    df.drop(labels=['deferred_2Y_a_DC', 'deferred_2Y_d_DC'], axis=1, inplace=True)\n",
    "    \n",
    "    #Three-Year\n",
    "    df['deferred_3Y_DC'] = df['deferred_3Y_a_DC']+df['deferred_3Y_d_DC']\n",
    "    df.drop(labels=['deferred_3Y_a_DC', 'deferred_3Y_d_DC'], axis=1, inplace=True)\n",
    "    \n",
    "    # renaming 3M and 6M\n",
    "    df.rename(index=str, columns = {'deferred_3M_d_DC':'deferred_3M_DC', \n",
    "                               'deferred_6M_d_DC': 'deferred_6M_DC'}, inplace=True)\n",
    "\n",
    "    # US columns\n",
    "    # Monthly\n",
    "    df['deferred_1M_US'] = df['deferred_1M_a_US']+df['deferred_1M_d_US']\n",
    "    df.drop(labels=['deferred_1M_a_US', 'deferred_1M_d_US'], axis=1, inplace=True)\n",
    "    \n",
    "    # Annual\n",
    "    df['deferred_1Y_US'] = df['deferred_1Y_a_US']+df['deferred_1Y_d_US']\n",
    "    df.drop(labels=['deferred_1Y_a_US', 'deferred_1Y_d_US'], axis=1, inplace=True)\n",
    "    \n",
    "    # Two-Year\n",
    "    df['deferred_2Y_US'] = df['deferred_2Y_a_US']+df['deferred_2Y_d_US']\n",
    "    df.drop(labels=['deferred_2Y_a_US', 'deferred_2Y_d_US'], axis=1, inplace=True)\n",
    "    \n",
    "    # Three-Year\n",
    "    df['deferred_3Y_US'] = df['deferred_3Y_a_US']+df['deferred_3Y_d_US']\n",
    "    df.drop(labels=['deferred_3Y_a_US', 'deferred_3Y_d_US'], axis=1, inplace=True)\n",
    "    \n",
    "    # renaming 3M and 6M\n",
    "    df.rename(index=str, columns = {'deferred_3M_d_US':'deferred_3M_US', \n",
    "                               'deferred_6M_d_US': 'deferred_6M_US'}, inplace=True)\n",
    "\n",
    "    \n",
    "    #cleaning up the longer column names\n",
    "    df.rename(index=str, columns = {'curr': 'curr',\n",
    "                               'BU':'BU',\n",
    "                               'period':'period'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = sum_USD_amt(list_df, list_columns)\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.loc['deferred_1M_d']+total_df.loc['deferred_1M_a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to create a summary report with totals coming from every area to make sure the totals I have make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this a function to be cleaned up somehow\n",
    "del dfr\n",
    "del dfr_a\n",
    "del dfr_b\n",
    "del dfr_d\n",
    "del gb_a\n",
    "del gb_a_1M\n",
    "del gb_a_1Y\n",
    "del gb_a_2Y\n",
    "del gb_a_3Y\n",
    "del gb_b, \n",
    "del gb_d\n",
    "del gb_svc, gb_rec, gb_d_two_yrs\n",
    "del gb_d_qtrly, gb_d_semi_ann\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now working on the ZCC billings\n",
    "\n",
    "These billings are type D billings that did not populate the rebill_rule field of the database.\n",
    "\n",
    "They have a 'sales document type' = 'ZCC\"\n",
    "\n",
    "The billings themselves are being created from a tableau report that looks for additions to the deferred revenue waterfall based on billings of type D and have a sales document type of ZCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE DONE:\n",
    "\n",
    "1. Clean up the type F billings (at least check to see if they are necessary)\n",
    "2. Make a function to delete all intermediate dataframes\n",
    "3. Add type A no config function\n",
    "4. Add type D ZCC billings\n",
    "\n",
    "5. Work on the forecast part of this\n",
    "\n",
    "6. Load up FX rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Adobe financial calendar and calculating period weeks\n",
    "df_cal = pd.read_excel('../data/old/ADOBE_FINANCIAL_CALENDAR.xlsx', 'ADBE_cal')\n",
    "df_cal['Period_Weeks'] = (df_cal['Per_End']-df_cal['Per_Start'])/np.timedelta64(1, 'W')\n",
    "df_cal['Period_Weeks']=df_cal['Period_Weeks'].astype(int)\n",
    "df_cal['Period_Weeks'] = df_cal['Period_Weeks']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type A No Config Type Billings\n",
    "\n",
    "This file contains type A billings that have a revenue contract start date and end date. We need to map these into the terms of our dataframe.\n",
    "\n",
    "### Steps:\n",
    "1. Rename the columns\n",
    "2. This file has entries for pennies. Need to clear out anything less than $10 in absolute value\n",
    "3. Determine the length of time between start date and end date\n",
    "4. Group this dataframe by currency, period and BU\n",
    "5. Merge this final dataframe with the larger dataframe\n",
    "\n",
    "## NOTE: This file contains two different start date and end date columns. We need to look at all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_excel('../data/all_billings_inputs.xlsx', sheet_name='type_A_no_config')\n",
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.rename(index=str, columns={'Document Currency':'curr', \n",
    "                               'Enterprise BU Desc':'BU',\n",
    "                               'Invoice Fiscal Year Period Desc':'period',\n",
    "                               'Rev Rec Contract End Date Hdr':'end_date_1',\n",
    "                               'Rev Rec Contract End Date Item':'end_date_2',\n",
    "                               'Rev Rec Contract Start Date Hdr': 'start_date_1',\n",
    "                               'Rev Rec Contract Start Date Item': 'start_date_2',\n",
    "                               'Completed Sales ( DC )':'DC_amount',\n",
    "                               'Completed Sales': 'US_amount'\n",
    "                               }, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the duplicate dates by taking a max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['start_date_str'] = df_A[['start_date_1','start_date_2']].max(axis=1).astype(str)\n",
    "df_A['end_date_str'] = df_A[['end_date_1','end_date_2']].max(axis=1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['start_date'] = pd.to_datetime(df_A['start_date_str'])\n",
    "df_A['end_date'] = pd.to_datetime(df_A['end_date_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.drop(labels=['end_date_1', 'end_date_2', 'start_date_1', 'start_date_2',\n",
    "                  'start_date_str', 'end_date_str'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['month_interval']=(df_A['end_date']-df_A['start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['months']= (df_A['month_interval']/ np.timedelta64(1,'M')).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.month_interval.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I need to map the months into the different integers in my dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rebills = [1, 3, 6, 12, 24, 36]\n",
    "temp_rebill = np.zeros_like(df_A['months'])\n",
    "for i in range(len(df_A)):\n",
    "    temp_rebill[i] = min(list_rebills, key=lambda x:abs(x-df_A['months'][i]))\n",
    "df_A['rebill_months']=temp_rebill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_A['months'], df_A['rebill_months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the dataframe by rebill_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop what we dont need\n",
    "df_A.drop(columns = ['start_date', 'end_date', 'month_interval', 'months'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.rename(index = str, columns={'currency': 'curr', 'Enterprise BU Desc':'BU', \n",
    "             'Invoice Fiscal Year Period Desc': 'period'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')\n",
    "temp_DC = df_A.pivot_table('DC_amount', ['curr', 'BU', 'period'], 'rebill_months')\n",
    "temp_US = df_A.pivot_table('US_amount', ['curr', 'BU', 'period'], 'rebill_months')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_DC = temp_DC.fillna(0)\n",
    "temp_US = temp_DC.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flat_DC = pd.DataFrame(temp_DC.to_records())\n",
    "temp_flat_US = pd.DataFrame(temp_US.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flat_DC.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flat_DC.rename(index=str, columns={'1.0':'deferred_1M_DC', \n",
    "                               '3.0':'deferred_3M_DC',\n",
    "                               '6.0':'deferred_6M_DC',\n",
    "                               '12.0':'deferred_1Y_DC',\n",
    "                               '24.0':'deferred_2Y_DC',\n",
    "                               '36.0': 'deferred_3Y_DC'}, inplace=True)\n",
    "\n",
    "temp_flat_US.rename(index=str, columns={'1.0':'deferred_1M_US', \n",
    "                               '3.0':'deferred_3M_US',\n",
    "                               '6.0':'deferred_6M_US',\n",
    "                               '12.0':'deferred_1Y_US',\n",
    "                               '24.0':'deferred_2Y_US',\n",
    "                               '36.0': 'deferred_3Y_US'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flat_DC.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dup = df.copy()\n",
    "print(len(df_test_dup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dup =df_test_dup.drop_duplicates(subset=['curr', 'BU', 'period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_test_dup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have to merge these two dataframes with the other billings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' def merge_new_dataframe(old_df, new_df, new_column):\n",
    "    df_merged = pd.merge(old_df, new_df, how='outer', \n",
    "                     left_on=['curr', 'BU', 'period'],\n",
    "                    right_on=['curr', 'BU', 'period'])\n",
    "    df_merged.rename(index=str, columns={'DC_amount': new_column+'_DC', 'US_amount': new_column+'_US'}, inplace=True)\n",
    "    \n",
    "    #need to drop the product configtype id for merges where the new_df is of type A\n",
    "    config_str = 'config'\n",
    "    rule_str = 'rebill_rule'\n",
    "    if config_str in df_merged.columns:\n",
    "        df_merged.drop(columns=['config'], inplace=True)\n",
    "    \n",
    "    if rule_str in df_merged.columns:\n",
    "        df_merged.drop(columns=['rebill_rule'], inplace=True)\n",
    "        \n",
    "    return df_merged\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flat_DC.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_A = pd.merge(df, temp_flat_DC, how='outer',\n",
    "                    left_on= ['curr', 'BU', 'period'],\n",
    "                    right_on=['curr', 'BU', 'period'], indicator=True, validate='one_to_one')\n",
    "#df_with_A = df_with_A.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_A = df_with_A.fillna({col: scalar for col in df.columns})\n",
    "df_with_A = df_with_A.fillna(pd.Series(0, index=df_with_A.select_dtypes(exclude='category').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_A.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all = pd.merge(df_with_A, temp_flat_US, how='outer',\n",
    "                    left_on= ['curr', 'BU', 'period'],\n",
    "                    right_on=['curr', 'BU', 'period'])\n",
    "#df_with_all = df_with_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all = df_with_all.fillna(pd.Series(0, index=df_with_all.select_dtypes(exclude='category').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all['deferred_1M_DC']= df_with_all['deferred_1M_DC_x']+df_with_all['deferred_1M_DC_y']\n",
    "df_with_all['deferred_3M_DC']= df_with_all['deferred_3M_DC_x']+df_with_all['deferred_3M_DC_y']\n",
    "df_with_all['deferred_6M_DC']= df_with_all['deferred_6M_DC_x']+df_with_all['deferred_6M_DC_y']\n",
    "df_with_all['deferred_1Y_DC']= df_with_all['deferred_1Y_DC_x']+df_with_all['deferred_1Y_DC_y']\n",
    "df_with_all['deferred_2Y_DC']= df_with_all['deferred_2Y_DC_x']+df_with_all['deferred_2Y_DC_y']\n",
    "df_with_all['deferred_3Y_DC']= df_with_all['deferred_3Y_DC_x']+df_with_all['deferred_3Y_DC_y']\n",
    "\n",
    "df_with_all['deferred_1M_US']= df_with_all['deferred_1M_US_x']+df_with_all['deferred_1M_US_y']\n",
    "df_with_all['deferred_3M_US']= df_with_all['deferred_3M_US_x']+df_with_all['deferred_3M_US_y']\n",
    "df_with_all['deferred_6M_US']= df_with_all['deferred_6M_US_x']+df_with_all['deferred_6M_US_y']\n",
    "df_with_all['deferred_1Y_US']= df_with_all['deferred_1Y_US_x']+df_with_all['deferred_1Y_US_y']\n",
    "df_with_all['deferred_2Y_US']= df_with_all['deferred_2Y_US_x']+df_with_all['deferred_2Y_US_y']\n",
    "df_with_all['deferred_3Y_US']= df_with_all['deferred_3Y_US_x']+df_with_all['deferred_3Y_US_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all.drop(labels = ['deferred_1M_DC_x','deferred_1M_DC_y',\n",
    "                        'deferred_3M_DC_x','deferred_3M_DC_y',\n",
    "                        'deferred_6M_DC_x','deferred_6M_DC_y',\n",
    "                        'deferred_1Y_DC_x','deferred_1Y_DC_y',\n",
    "                        'deferred_2Y_DC_x','deferred_2Y_DC_y',\n",
    "                        'deferred_3Y_DC_x','deferred_3Y_DC_y',\n",
    "                        'deferred_1M_US_x','deferred_1M_US_y',   \n",
    "                        'deferred_3M_US_x','deferred_3M_US_y',\n",
    "                        'deferred_6M_US_x','deferred_6M_US_y',\n",
    "                        'deferred_1Y_US_x','deferred_1Y_US_y',\n",
    "                        'deferred_2Y_US_x','deferred_2Y_US_y',\n",
    "                        'deferred_3Y_US_x','deferred_3Y_US_y'],\n",
    "                 axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all['deferred_1Y_US'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deferred_1Y_US'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sum of temp flat DC 1M', temp_flat_DC['deferred_1M_DC'].sum())\n",
    "print('sum of base_df before DC 1M', df['deferred_1M_DC'].sum())\n",
    "print('sum of final DC 1M', df_with_all['deferred_1M_DC'].sum())\n",
    "\n",
    "a = temp_flat_DC['deferred_1M_DC'].sum()\n",
    "b = df['deferred_1M_DC'].sum()\n",
    "c = df_with_all['deferred_1M_DC'].sum()\n",
    "print(c)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deferred_1M_DC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flat_DC['deferred_1M_DC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_all['deferred_1M_DC'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to create a table that contains the total billings by DC for each dataframe and each step for auditing\n",
    "\n",
    " - start with all of the DC\n",
    " - then create function that appends and adds rows\n",
    " - then do the same for the DC stuff type_A\n",
    " - then check the totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_with_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index= df[df['period']=='2020-04'].index\n",
    "df.drop(drop_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the pickle\n",
    "#pickle.dump(df, open('../data/processed/all_billings.p', 'wb'))\n",
    "\n",
    "# open the pickle file\n",
    "df = pickle.load(open('../data/processed/all_billings.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['period'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading All of the other information we need here\n",
    " - filename = currency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curr_map= pd.read_excel('../data/currency_map.xlsx', sheet_name='curr_map')\n",
    "df_curr_map['Country'] = df_curr_map['Country'].str.replace('\\(MA\\)', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FX_rates = pd.read_excel('../data/FX_data.xlsx', sheet_name='to_matlab')\n",
    "df_FX_rates['VOL_3M'] = df_FX_rates['VOL_3M']/100\n",
    "df_FX_rates['VOL_6M'] = df_FX_rates['VOL_6M']/100\n",
    "df_FX_rates['VOL_9M'] = df_FX_rates['VOL_9M']/100\n",
    "df_FX_rates['VOL_1Y'] = df_FX_rates['VOL_1Y']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FX_fwds = pd.read_excel('../data/FX_forward_rates.xlsx', sheet_name='forward_data', \n",
    "                          skiprows = 1, usecols=\"C,G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FX_fwds.rename(index=str, columns={'Unnamed: 2': 'curr', 'FWD REF':'forward'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the func_load_bookings now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings = pd.read_excel('../data/2020_bookings_fcst_Q1.xlsx', sheet_name='bookings')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the bookings data\n",
    " - remove odd strings such as '(EB)' from BU\n",
    " - (IS) from internal segment\n",
    " - etc\n",
    " \n",
    " \n",
    " NOTE: The '(' is a special character so we need to precede these with the escape character '\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['EBU'] = df_bookings['EBU'].str.replace(' \\(EB\\)', '', case=False)\n",
    "df_bookings['Internal Segment'] = df_bookings['Internal Segment'].str.replace('\\(IS\\)', '')\n",
    "\n",
    "df_bookings['PMBU'] = df_bookings['PMBU'].str.replace('\\(PMBU\\)', '')\n",
    "df_bookings['GEO'] = df_bookings['GEO'].str.replace('\\(G\\)', '')\n",
    "df_bookings['Market Area'] = df_bookings['Market Area'].str.replace('\\(MA\\)', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.EBU.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.PMBU.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.GEO.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['Mark Segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['Bookings Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['Scenario'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['FX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.drop(columns = ['Hedge', 'Mark Segment', 'Type', 'Scenario', 'FX'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.rename(index=str, columns = {'EBU': 'BU', \n",
    "                                        'Internal Segment': 'segment',\n",
    "                                        'PMBU': 'product',\n",
    "                                        'GEO':'geo',\n",
    "                                        'Market Area': 'country',\n",
    "                                        'Bookings Type': 'booking_type',\n",
    "                                        'value': 'US_amount'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curr_map.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_book_ctry = df_bookings['country'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_curr_map = df_curr_map['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(set(list_book_ctry) & set(list_curr_map))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_map = set(list_book_ctry).difference(set(list_curr_map))\n",
    "not_in_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_map = set()\n",
    "not_in_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_in_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings = pd.merge(df_bookings, df_curr_map, how='left', left_on='country', right_on='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to move the period_weeks from the Adobe calendar to the billings and bookings dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to add the period_weeks data to both the df_bookings and df_billings dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create a column in the df_cal with both the year then '-' and the last two digits of the per_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal['p2digit']=df_cal['Period'].astype(str)\n",
    "df_cal['p2digit']=df_cal['p2digit'].str.zfill(2)\n",
    "df_cal['period_match']=df_cal['Year'].astype(str) + '-' + df_cal['p2digit'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.drop(['p2digit'],axis=1, inplace=True)\n",
    "df_cal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_2_merge = df_cal.copy()\n",
    "df_cal_2_merge.drop(['Year', 'Quarter', 'Period', 'Qtr_Ticker', 'Qtr_Start', 'Qtr_End', 'Per_Start',\n",
    "                     'Per_Ticker','Per_End'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_cal_2_merge, how='left', left_on='period', right_on='period_match')\n",
    "df.drop(['period_match', '_merge'], axis=1, inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I need to merge the period weeks with the df_fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_billings=df_billings.sort_values(['curr', 'BU', 'period'], ascending = (True, True, True))\n",
    "\n",
    "input_df_dict = {'billings':df, \n",
    "              'ADBE_cal':df_cal,\n",
    "              'bookings': df_bookings,\n",
    "              'FX_forwards': df_FX_fwds,\n",
    "              'FX_rates': df_FX_rates\n",
    "                }\n",
    "\n",
    "pickle.dump(input_df_dict, open('../data/processed/all_inputs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def join_new_dataframe(old_df, new_df, new_column):\n",
    "    df_joined = old_df.join(new_df, how='outer')\n",
    "    df_joined.rename(index=str, columns={'DC_amount': new_column+'_DC', 'US_amount': new_column+'_US'}, inplace=True)\n",
    "    df_joined.fillna(value=0, inplace=True)\n",
    "    \n",
    "    #need to drop the product configtype id for merges where the new_df is of type A\n",
    "    config_str = 'config'\n",
    "    rule_str = 'rebill_rule'\n",
    "    if config_str in df_joined.columns:\n",
    "        df_joined.drop(columns=['config'], inplace=True)\n",
    "    \n",
    "    if rule_str in df_joined.columns:\n",
    "        df_joined.drop(columns=['rebill_rule'], inplace=True)\n",
    "        \n",
    "    return df_joined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def join_all_dataframes(list_df, list_columns):\n",
    "    for i, df in enumerate(list_df):\n",
    "        print('This is i:', i)\n",
    "        print('referencing the column: ', list_columns[i])\n",
    "        #print(df.columns)\n",
    "        # setting the index to be 'curr', 'BU' and 'period'\n",
    "        df.set_index(['curr', 'BU', 'period'], drop=True, inplace=True, verify_integrity=True)\n",
    "        print(df.head(4))\n",
    "        #if i==0:\n",
    "            #df_joined = df.copy()\n",
    "            #df_joined = list_df[0].copy()\n",
    "            #df_joined.rename(index=str, columns={'DC_amount': list_columns[i]+'_DC', \n",
    "            #                                     'US_amount': list_columns[i]+'_US'}, inplace=True)\n",
    "        #else:\n",
    "            #df_joined = join_new_dataframe(df_joined, df, list_columns[i])\n",
    "\n",
    "    #return df_joined\n",
    "    x=1\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
