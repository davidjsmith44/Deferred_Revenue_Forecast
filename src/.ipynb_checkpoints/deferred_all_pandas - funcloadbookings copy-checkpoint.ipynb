{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Deferred Revenue in Python\n",
    "Will this be easier for everyone to use than Matlab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Base Billings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/Data_2019_P06/base_billings.xlsx', sheet_name='bill_DC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Currency</th>\n",
       "      <th>Enterprise Bu</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Invoicing Fiscal Year-Period Desc</th>\n",
       "      <th>Product Configtype ID</th>\n",
       "      <th>Revenue Recognition Category New</th>\n",
       "      <th>Rule For Bill Date</th>\n",
       "      <th>Sales Type</th>\n",
       "      <th>Subscription Term</th>\n",
       "      <th>Completed Sales Doc Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>EUR</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>MTHLY</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>2219994.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>AUD</td>\n",
       "      <td>Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>1Y</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>17444.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>CAD</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>CERT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECOGNIZED</td>\n",
       "      <td>0</td>\n",
       "      <td>-198800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>CHF</td>\n",
       "      <td>Document Cloud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>23140.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25772</th>\n",
       "      <td>USD</td>\n",
       "      <td>Creative</td>\n",
       "      <td>ONGO</td>\n",
       "      <td>2015-08</td>\n",
       "      <td>1Y</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31889</th>\n",
       "      <td>USD</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>CERT</td>\n",
       "      <td>2018-09</td>\n",
       "      <td>1Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECOGNIZED</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>AUD</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>ONGO</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>YC</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>129976.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32893</th>\n",
       "      <td>USD</td>\n",
       "      <td>Print &amp; Publishing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>Y3</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>1</td>\n",
       "      <td>279126.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33677</th>\n",
       "      <td>USD</td>\n",
       "      <td>Print &amp; Publishing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>1Y</td>\n",
       "      <td>D</td>\n",
       "      <td>YA</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>12</td>\n",
       "      <td>876939.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30982</th>\n",
       "      <td>USD</td>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>1TME</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>OCONS</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFERRED</td>\n",
       "      <td>0</td>\n",
       "      <td>1180115.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document Currency       Enterprise Bu Frequency  \\\n",
       "9756                EUR            Creative       NaN   \n",
       "372                 AUD            Creative       NaN   \n",
       "4556                CAD    Experience Cloud      CERT   \n",
       "5806                CHF      Document Cloud       NaN   \n",
       "25772               USD            Creative      ONGO   \n",
       "31889               USD    Experience Cloud      CERT   \n",
       "2876                AUD    Experience Cloud      ONGO   \n",
       "32893               USD  Print & Publishing       NaN   \n",
       "33677               USD  Print & Publishing       NaN   \n",
       "30982               USD    Experience Cloud      1TME   \n",
       "\n",
       "      Invoicing Fiscal Year-Period Desc Product Configtype ID  \\\n",
       "9756                            2019-01                 MTHLY   \n",
       "372                             2016-12                    1Y   \n",
       "4556                            2017-03                   NaN   \n",
       "5806                            2016-04                    1Y   \n",
       "25772                           2015-08                    1Y   \n",
       "31889                           2018-09                    1Y   \n",
       "2876                            2018-08                    1Y   \n",
       "32893                           2015-06                    1Y   \n",
       "33677                           2018-08                    1Y   \n",
       "30982                           2017-08                 OCONS   \n",
       "\n",
       "      Revenue Recognition Category New Rule For Bill Date  Sales Type  \\\n",
       "9756                                 D                 Y3    DEFERRED   \n",
       "372                                  A                NaN    DEFERRED   \n",
       "4556                               NaN                NaN  RECOGNIZED   \n",
       "5806                                 D                 Y3    DEFERRED   \n",
       "25772                                A                NaN    DEFERRED   \n",
       "31889                              NaN                NaN  RECOGNIZED   \n",
       "2876                                 D                 YC    DEFERRED   \n",
       "32893                                D                 Y3    DEFERRED   \n",
       "33677                                D                 YA    DEFERRED   \n",
       "30982                                B                NaN    DEFERRED   \n",
       "\n",
       "       Subscription Term  Completed Sales Doc Currency  \n",
       "9756                   1                    2219994.40  \n",
       "372                    1                      17444.17  \n",
       "4556                   0                    -198800.00  \n",
       "5806                   1                      23140.78  \n",
       "25772                  0                      20000.00  \n",
       "31889                  0                          0.00  \n",
       "2876                   0                     129976.00  \n",
       "32893                  1                     279126.44  \n",
       "33677                 12                     876939.37  \n",
       "30982                  0                    1180115.35  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bookings(basepath, sheetname):\n",
    "\n",
    "    #load spreadsheets\n",
    "    bf = pd.read_excel(basepath, sheet_name=sheetname)\n",
    "    curr_map = pd.read_excel('../data/Data_2019_P06/currency_map.xlsx', 'curr_map')\n",
    "#    FX_rates = pd.read_excel('../data/Data_2019_P06/FX_data.xlsx', 'to_matlab')\n",
    "    \n",
    "    \n",
    "    #clean data: remove bracketed terms and blank spaces from the ends of the fields\n",
    "    bf['EBU'] = bf['EBU'].str.split(r'\\s*\\(').str[0]\n",
    "    bf['Market Area'] = bf['Market Area'].str.split(r'\\s*\\(').str[0]\n",
    "\n",
    "#    bf['Internal Segment'] = bf['Internal Segment'].str.split(r'\\s*\\(').str[0]\n",
    "#    bf['PMBU'] = bf['PMBU'].str.split(r'\\s*\\(').str[0]\n",
    "#    bf['Geo'] = bf['Geo'].str.split(r'\\s*\\(').str[0]\n",
    "\n",
    "  \n",
    "    #currency by market area dictionary - strip out ' (MA)' from market area\n",
    "    curr_map['Country'] = curr_map['Country'].map(lambda x: x.rstrip(' (MA)'))\n",
    "    #convert to dictionary \n",
    "    curr_map=dict(curr_map.values.tolist())\n",
    "    \n",
    "    # add column and populate with the currency associated with the market area\n",
    "    bf['Currency'] = bf['Market Area'].map(curr_map)\n",
    "    \n",
    "    #eliminate extra columns from the bookings data by selecting only the desired columns to be included \n",
    "    bf = bf[['EBU','Fiscal Quarter','Value','Currency']]\n",
    "    \n",
    "    #summarize the dataframe by EBU, Currency and Fiscal Quarter\n",
    "    bf = bf.groupby(['EBU','Currency','Fiscal Quarter'], as_index=False).sum()\n",
    "            \n",
    "    return bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_currencymap(basepath, sheetname):\n",
    "    # load the currency map and make a dictionary out of it to be used with loading the bookings data\n",
    "    # note the file name and location are hard coded in the 'load_bookings' function.\n",
    "    cmdf = pd.read_excel(basepath, sheet_name=sheetname)\n",
    "    cmdf['Country'] = cmdf['Country'].map(lambda x: x.rstrip(' (MA)'))\n",
    "    cmdic=dict(cmdf.values.tolist())\n",
    "    return cmdic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EBU</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Fiscal Quarter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>AUD</td>\n",
       "      <td>Q1 2019</td>\n",
       "      <td>1.771951e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creative</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Q1 2019</td>\n",
       "      <td>2.102105e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Q3 2019</td>\n",
       "      <td>1.890005e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creative</td>\n",
       "      <td>AUD</td>\n",
       "      <td>Q4 2019</td>\n",
       "      <td>6.606757e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Document Cloud</td>\n",
       "      <td>USD</td>\n",
       "      <td>Q2 2019</td>\n",
       "      <td>3.463121e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Print &amp; Publishing</td>\n",
       "      <td>USD</td>\n",
       "      <td>Q4 2019</td>\n",
       "      <td>4.511444e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Document Cloud</td>\n",
       "      <td>AUD</td>\n",
       "      <td>Q4 2019</td>\n",
       "      <td>4.368968e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Document Cloud</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Q3 2019</td>\n",
       "      <td>2.725734e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Experience Cloud</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Q2 2019</td>\n",
       "      <td>5.939052e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Creative</td>\n",
       "      <td>USD</td>\n",
       "      <td>Q4 2019</td>\n",
       "      <td>8.528388e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   EBU Currency Fiscal Quarter         Value\n",
       "40    Experience Cloud      AUD        Q1 2019  1.771951e+07\n",
       "4             Creative      EUR        Q1 2019  2.102105e+07\n",
       "54    Experience Cloud      JPY        Q3 2019  1.890005e+07\n",
       "3             Creative      AUD        Q4 2019  6.606757e+06\n",
       "37      Document Cloud      USD        Q2 2019  3.463121e+07\n",
       "75  Print & Publishing      USD        Q4 2019  4.511444e+06\n",
       "23      Document Cloud      AUD        Q4 2019  4.368968e+06\n",
       "34      Document Cloud      JPY        Q3 2019  2.725734e+06\n",
       "45    Experience Cloud      EUR        Q2 2019  5.939052e+07\n",
       "19            Creative      USD        Q4 2019  8.528388e+07"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf = load_bookings('../data/Data_2019_P06/2019_bookings_fcst.xlsx','bookings')\n",
    "bdf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the column names early since they are inconsistent across other reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index = str, columns = {'Document Currency': 'curr',\n",
    "                                 'Enterprise Bu': 'BU',\n",
    "                                 'Invoicing Fiscal Year-Period Desc': 'period',\n",
    "                                 'Product Configtype ID': 'config',\n",
    "                                 'Rule For Bill Date': 'rebill_rule',\n",
    "                                 'Completed Sales Doc Currency': 'amount'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any currency that has  < 10 transactions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of the currencies and the number of transactions for each currency\n",
    "vc = df['curr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable that is true if the number of transaction is greater than 10, false otherwise\n",
    "keep_these = vc.values > 10\n",
    "# filtering only currencies that were greater than 10\n",
    "keep_curr = vc[keep_these]\n",
    "a = keep_curr.index\n",
    "# filtering the dataframe to remove any of teh currencies not in our list\n",
    "df = df[df['curr'].isin(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just keeping track of the currencies we removed in our model_dict data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_these = vc.values <= 10\n",
    "model_dict = {'curr_removed': list(vc[remove_these].index)}\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing any of the values that are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is the length of the dataframe before removing zeros: ', len(df))\n",
    "df = df[df['amount']!=0]\n",
    "print('This is the length of the dataframe after removing zeros: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing out the Non-Revenue billings from the file\n",
    " - No Idea what these are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of the dataframe before removing non-revenue billings: ', len(df))\n",
    "df = df[df['Sales Type']!='NON-REV']\n",
    "print('Length of the dataframe after removing non-revenue billings:  ', len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting to group the revenue by period, industry, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to group by the following categories\n",
    " - currency\n",
    " - period\n",
    " - sale type\n",
    " \n",
    "May need to process the data differently with the deferred billings so we will start with the recognized and then the service billings\n",
    "\n",
    "\n",
    "DOING THIS ALL IN PANDAS WITH SPLIT APPLY COMBINE on Sales Type \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the data into three dataframes\n",
    "# Recognized billings\n",
    "rec = df[df['Sales Type']=='RECOGNIZED']\n",
    "svc = df[df['Sales Type']=='PRO-SVC-INV']\n",
    "dfr = df[df['Sales Type']=='DEFERRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and group billings function will delete temporary datasets as completed\n",
    "def filter_and_group(data2process, gblist, billings_type=None):\n",
    "    \"\"\"filter and group Base Billings Data\"\"\"\n",
    "    \n",
    "    #when a billings_type is supplied then filter, else just go to groupby below\n",
    "    if billings_type:\n",
    "        data2process = data2process[data2process['Revenue Recognition Category New']==billings_type]\n",
    "    \n",
    "    #groupby the columns passed in the function call then remove the subscription term column\n",
    "    gb = data2process.groupby(gblist, as_index=False).sum()\n",
    "    gb.drop(labels='Subscription Term', axis=1, inplace = True)\n",
    "    return gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rec = filter_and_group( rec, ['curr', 'BU', 'period'])\n",
    "gb_svc = filter_and_group( svc, ['curr', 'BU', 'period'])\n",
    "gb_a = filter_and_group(dfr, ['curr', 'BU', 'period', 'config'],  'A')\n",
    "gb_b = filter_and_group(dfr,['curr', 'BU', 'period'],  'B')\n",
    "gb_d = filter_and_group(dfr,['curr', 'BU', 'period',\n",
    "                     'rebill_rule'], 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rec.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW WORKING ON THE BILLINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognized Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rec.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing groupby object\n",
    "#gb_rec = rec.groupby(['curr', 'BU', 'period'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Subscription term hangs around. We are dropping that here\n",
    "#gb_rec.drop(labels='Subscription Term', axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_rec.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(type(gb_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Billings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing groupby object\n",
    "#gb_svc = svc.groupby(['curr', 'BU', 'period'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_svc.drop(labels='Subscription Term', axis=1,inplace =True)\n",
    "#gb_svc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WORKING ON DEFERRED BILLINGS\n",
    "\n",
    "Type B billings are service agreements that will have invoices submitted before the billings are reclassified to revenue. If no invoices are assigned to the billings, the billings become revenue in 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the type B first then do a group_by\n",
    "#dfr_b = dfr[dfr['Revenue Recognition Category New']=='B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_b = dfr_b.groupby(['curr', 'BU', 'period'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_b.drop(labels='Subscription Term', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_b.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('length of deferred billings : ', len(dfr))\n",
    "#print('length of the type B billings: ', len(dfr_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Type A Billings\n",
    "These billings are on a billing plan. The product config tells us how long before they renew\n",
    "\n",
    " - '2Y' = 24 months\n",
    " - '1Y' = 12 months\n",
    " - 'MTHLY' = 1 month\n",
    " \n",
    "NOTE: There are also other fields in the 'Product Configtype ID' field that do not map well to a rebill period.\n",
    "To fix this, we need to load up a different file and determine the length of the sales contract (type A no config)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering just the type A billings\n",
    "#dfr_a = dfr[dfr['Revenue Recognition Category New']=='A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_a = dfr_a.groupby(['curr', 'BU', 'period',\n",
    "#                     'config'], as_index=False).sum()\n",
    "#gb_a.drop(labels='Subscription Term', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a['config'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is just a check to see how large the billing types are across all periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a_config = gb_a.groupby(['config'], as_index=False).sum()\n",
    "gb_a_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These 'OCONS', 'ONORE' and 'OUNIV' data types are not actual product config IDs so we have to get them from a different data file. We are excluding these types below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = ['1Y', '2Y', '3Y', 'MTHLY']\n",
    "test1 = gb_a['config'].isin(config_list)\n",
    "sum(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = gb_a[gb_a['config'].isin(config_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For now, lets just split this into gb_a_1Y, gb_a_2Y, gb_a_3y, gb_a_1M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_a_1Y = test1[test1['config']=='1Y']\n",
    "gb_a_2Y = test1[test1['config']=='2Y']\n",
    "gb_a_3Y = test1[test1['config']=='3Y']\n",
    "gb_a_1M = test1[test1['config']=='MTHLY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('this is the lenght of type A 1M billings: ', len(gb_a_1M))\n",
    "print('this is the lenght of type A 1Y billings: ', len(gb_a_1Y))\n",
    "print('this is the lenght of type A 2Y billings: ', len(gb_a_2Y))\n",
    "print('this is the lenght of type A 3Y billings: ', len(gb_a_3Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE D billings\n",
    "These billings have a field 'Rule For Bill Date' that determines when new billings will occur\n",
    " - Monthly [Y1, Y2, Y3, Y5]\n",
    " - Quarterly [YQ]\n",
    " - Every 4 months [YT]\n",
    " - Semi-annual [YH]\n",
    " - Annual [YA, YC]\n",
    " - Every 2 years - [Y4]\n",
    " \n",
    " We also need to track the type D billings that do not have a 'Rule for Bill Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now just do a groupby on the type\n",
    "# filtering just the type A billings\n",
    "#dfr_d = dfr[dfr['Revenue Recognition Category New']=='D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_d = dfr_d.groupby(['curr', 'BU', 'period',\n",
    "#                     'rebill_rule'], as_index=False).sum()\n",
    "#gb_d.drop(labels='Subscription Term', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_d_mthly = gb_d[gb_d['rebill_rule'].isin(['Y1', 'Y2', 'Y3', 'Y5'])]\n",
    "gb_d_qtrly = gb_d[gb_d['rebill_rule']=='YQ']\n",
    "gb_d_four_mths = gb_d[gb_d['rebill_rule']=='YT']\n",
    "gb_d_semi_ann = gb_d[gb_d['rebill_rule']=='YH']\n",
    "gb_d_annual = gb_d[gb_d['rebill_rule'].isin(['YA', 'YC'])]\n",
    "gb_d_two_yrs = gb_d[gb_d['rebill_rule']=='Y4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_d['rebill_rule'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: There is one type D billings that is listed as 'BT' I don't know what this means, but it was a $180 EUR payment from January 2017, so we will ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of monthly', len(gb_d_mthly))\n",
    "print('Length of quarterly', len(gb_d_qtrly))\n",
    "print('Length of four months', len(gb_d_four_mths))\n",
    "print('Length of semi ann', len(gb_d_semi_ann))\n",
    "print('Length of annual', len(gb_d_annual))\n",
    "print('Length of two years', len(gb_d_two_yrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_is_BT = gb_d[gb_d['rebill_rule']=='YT']\n",
    "what_is_BT.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: There are only 8 payments (back from 2017) that paid on a 4 month basis. \n",
    "We will ignore these as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW WE NEED TO BUILD A DATAFRAME THAT INTEGRATES THIS DATA\n",
    "\n",
    "- We will have the following descriptive fields\n",
    "   - Invoicing Fiscal Year-Period\n",
    "   - Document Currency\n",
    "   - Enterprise BU\n",
    "\n",
    "- We will have the following fields based on rebilling rule\n",
    "   - Recognized\n",
    "   - Service\n",
    "   - Monthly\n",
    "   - Quarterly\n",
    "   - Annual\n",
    "   - Two Years\n",
    "   - Three Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do it this way when we get to a .py file!\n",
    "list_df = [gb_rec, gb_svc, gb_b,\n",
    "        gb_a_1M,    gb_a_1Y,    gb_a_2Y,       gb_a_3Y, \n",
    "        gb_d_mthly, gb_d_qtrly, gb_d_semi_ann, gb_d_annual, gb_d_two_yrs]\n",
    "\n",
    "list_columns = ['recognized', 'service', 'deferred_B', \n",
    "    'deferred_1M_a', 'deferred_1Y_a', 'deferred_2Y_a', 'deferred_3Y_a',\n",
    "    'deferred_1M_d', 'deferred_3M_d', 'deferred_6M_d', 'deferred_1Y_d', 'deferred_2Y_d']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_new_dataframe(old_df, new_df, new_column):\n",
    "    df_merged = pd.merge(old_df, new_df, how='outer', \n",
    "                     left_on=['curr', 'BU', 'period'],\n",
    "                    right_on=['curr', 'BU', 'period'])\n",
    "    df_merged.rename(index=str, columns={'amount': new_column}, inplace=True)\n",
    "    \n",
    "    #need to drop the product configtype id for merges where the new_df is of type A\n",
    "    config_str = 'config'\n",
    "    rule_str = 'rebill_rule'\n",
    "    if config_str in df_merged.columns:\n",
    "        df_merged.drop(columns=['config'], inplace=True)\n",
    "    \n",
    "    if rule_str in df_merged.columns:\n",
    "        df_merged.drop(columns=['rebill_rule'], inplace=True)\n",
    "        \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_dataframes(list_df, list_columns):\n",
    "    for i, df in enumerate(list_df):\n",
    "        print('This is i:', i)\n",
    "        #print(\"This is the df: \", df.head())\n",
    "        print('referencing the column: ', list_columns[i])\n",
    "\n",
    "        if i==0:\n",
    "            df_merged = list_df[0]\n",
    "            df_merged.rename(index=str, columns={'amount': list_columns[i]}, inplace=True)\n",
    "        else:\n",
    "            df_merged = merge_new_dataframe(df_merged, df, list_columns[i])\n",
    "\n",
    "    return df_merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_all_dataframes(list_df, list_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_columns(df):\n",
    "    \n",
    "    # clean up NaNs before adding \n",
    "    df = df.fillna(value=0)\n",
    "    \n",
    "    # Monthly\n",
    "    df['deferred_1M'] = df['deferred_1M_a']+df['deferred_1M_d']\n",
    "    df.drop(labels=['deferred_1M_a', 'deferred_1M_d'], axis=1, inplace=True)\n",
    "    \n",
    "    # Annual\n",
    "    df['deferred_1Y'] = df['deferred_1Y_a']+df['deferred_1Y_d']\n",
    "    df.drop(labels=['deferred_1Y_a', 'deferred_1Y_d'], axis=1, inplace=True)\n",
    "    \n",
    "    # Two-Year\n",
    "    df['deferred_2Y'] = df['deferred_2Y_a']+df['deferred_2Y_d']\n",
    "    df.drop(labels=['deferred_2Y_a', 'deferred_2Y_d'], axis=1, inplace=True)\n",
    "    \n",
    "    # renaming 3Y, 3M and 6M\n",
    "    df.rename(index=str, columns = {'deferred_3Y_a':'deferred_3Y', 'deferred_3M_d':'deferred_3M', \n",
    "                               'deferred_6M_d': 'deferred_6M'}, inplace=True)\n",
    "\n",
    "    #cleaning up the longer column names\n",
    "    df.rename(index=str, columns = {'curr': 'curr',\n",
    "                               'BU':'BU',\n",
    "                               'period':'period'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this a function to be cleaned up somehow\n",
    "del dfr\n",
    "#del dfr_a\n",
    "#del dfr_b\n",
    "#del dfr_d\n",
    "del gb_a\n",
    "del gb_a_1M\n",
    "del gb_a_1Y\n",
    "del gb_a_2Y\n",
    "del gb_a_3Y\n",
    "del gb_b, \n",
    "del gb_d\n",
    "del gb_svc, gb_rec, gb_d_two_yrs\n",
    "del gb_d_four_mths, gb_d_qtrly, gb_d_semi_ann\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now working on the ZCC billings\n",
    "\n",
    "These billings are type D billings that did not populate the rebill_rule field of the database.\n",
    "\n",
    "They have a 'sales document type' = 'ZCC\"\n",
    "\n",
    "The billings themselves are being created from a tableau report that looks for additions to the deferred revenue waterfall based on billings of type D and have a sales document type of ZCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE DONE:\n",
    "\n",
    "1. Clean up the type F billings (at least check to see if they are necessary)\n",
    "2. Make a function to delete all intermediate dataframes\n",
    "3. Add type A no config function\n",
    "4. Add type D ZCC billings\n",
    "\n",
    "5. Work on the forecast part of this\n",
    "\n",
    "6. Load up FX rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adobe financial calendar\n",
    "df_cal = pd.read_excel('../data/Data_2019_P06/ADOBE_FINANCIAL_CALENDAR.xlsx', 'ADBE_cal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCC Billings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC = pd.read_excel('../data/Data_2019_P06/type_D_ZCC_billings.xlsx', sheet_name='DC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.rename(index = str, columns = {'Document Currency': 'curr',\n",
    "                                      'Enterprise BU Description':'BU',\n",
    "                                      'Rule for Bill Date Code': 'rebill_rule',\n",
    "                                      'Week of FICA Posting Date (YYYYMMDD) (copy)': 'fiscal_week',\n",
    "                                      'DF Additions - Doc Curr': 'amount'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that we do not have any currencies that need to be removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC['curr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZCC_curr = df_ZCC['curr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ZCC_curr:\n",
    "    if item in model_dict['curr_removed']:\n",
    "        print('This currency needs to be removed: ', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no currencies that need to be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are clearing out nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of NaNs to be cleared out: ', sum(df_ZCC['amount'].isna()))\n",
    "ZCC_isna = df_ZCC['amount'].isna()\n",
    "print(\"This is the length of the ZCC records before clearing NAs: \", len(df_ZCC))\n",
    "df_ZCC = df_ZCC[~ZCC_isna]\n",
    "print(\"This is the length of the ZCC records before clearing NAs: \", len(df_ZCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ZCC_periods(df_ZCC, df_cal):\n",
    "    ''' \n",
    "    Takes each ZCC period billing and maps it to the fiscal calendar then assignes the\n",
    "    ZCC billing to the dataframe df\n",
    "    '''\n",
    "    period_list = []\n",
    "    \n",
    "    for i in range(len(df_ZCC)):\n",
    "        # this_date is the date we need mapped to a period\n",
    "        this_date = df_ZCC['fiscal_week'].iloc[i]\n",
    "        \n",
    "        #max index will be the index to the period in our financial calendar\n",
    "        this_index = df_cal['Per_End']<=this_date\n",
    "        max_index = sum(this_index)\n",
    "\n",
    "        this_year = df_cal['Year'].iloc[max_index].astype(str)\n",
    "        this_period= df_cal['Period'].iloc[max_index].astype(str)\n",
    "\n",
    "        # formatting the period string from the calendar\n",
    "        if len(this_period)== 1:\n",
    "            this_period = '0'+this_period\n",
    "\n",
    "        period_ticker = this_year + '-' + this_period\n",
    "\n",
    "        period_list.append(period_ticker)\n",
    "\n",
    "    df_ZCC['period'] = period_list\n",
    "    return df_ZCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC = add_ZCC_periods(df_ZCC, df_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to determine the length of the ZCC billings to and add this to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_ZCC = df_ZCC.groupby(['curr', 'BU', 'period',\n",
    "                     'rebill_rule'], as_index=False).sum()\n",
    "#gb_d.drop(labels='Subscription Term', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_ZCC.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_ZCC['rebill_rule'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_ZCC_mthly = gb_ZCC[gb_ZCC['rebill_rule'].isin(['Y1', 'Y2', 'Y3', 'Y5'])]\n",
    "gb_ZCC_qtrly = gb_ZCC[gb_ZCC['rebill_rule']=='YQ']\n",
    "gb_ZCC_four_mths = gb_ZCC[gb_ZCC['rebill_rule']=='YT']\n",
    "gb_ZCC_semi_ann = gb_ZCC[gb_ZCC['rebill_rule']=='YH']\n",
    "gb_ZCC_annual = gb_ZCC[gb_ZCC['rebill_rule'].isin(['YA', 'YC'])]\n",
    "gb_ZCC_two_yrs = gb_ZCC[gb_ZCC['rebill_rule']=='Y4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no four month billings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gb_ZCC_four_mths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two YX billings for small amounts that I do not have mapped to a frequency.\n",
    "They will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_is_YX = gb_ZCC[gb_ZCC['rebill_rule']=='YX']\n",
    "what_is_YX.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I need to merge the ZCC billings and then clean up the columns. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do it this way when we get to a .py file!\n",
    "list_ZCC_df = [gb_ZCC_mthly, gb_ZCC_qtrly, gb_ZCC_semi_ann,\n",
    "           gb_ZCC_annual, gb_ZCC_two_yrs]\n",
    "\n",
    "list_ZCC_columns = ['deferred_1M', 'deferred_3M', 'deferred_6M', \n",
    "    'deferred_1Y', 'deferred_2Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC_merged = merge_all_dataframes(list_ZCC_df, list_ZCC_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC_merged.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing out any zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZCC_merged.drop(columns=['rebill_rule_x', 'rebill_rule_y'], inplace=True)\n",
    "df_ZCC_merged.fillna(0, inplace=True)\n",
    "df_ZCC_merged.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge = pd.merge(df, df_ZCC_merged, how='outer', \n",
    "                 left_on=['curr', 'BU', 'period'],\n",
    "                right_on=['curr', 'BU', 'period'])\n",
    "#test_merge.rename(index=str, columns={'amount': new_column}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean up NaNs before adding \n",
    "test_merge = test_merge.fillna(value=0)\n",
    "\n",
    "# Monthly\n",
    "test_merge['deferred_1M'] = test_merge['deferred_1M_x']+test_merge['deferred_1M_y']\n",
    "test_merge.drop(labels=['deferred_1M_x', 'deferred_1M_y'], axis=1, inplace=True)\n",
    "\n",
    "# Quarterly\n",
    "test_merge['deferred_3M'] = test_merge['deferred_3M_x']+test_merge['deferred_3M_y']\n",
    "test_merge.drop(labels=['deferred_3M_x', 'deferred_3M_y'], axis=1, inplace=True)\n",
    "\n",
    "# Semi-Annual\n",
    "test_merge['deferred_6M'] = test_merge['deferred_6M_x']+test_merge['deferred_6M_y']\n",
    "test_merge.drop(labels=['deferred_6M_x', 'deferred_6M_y'], axis=1, inplace=True)\n",
    "\n",
    "# Annual\n",
    "test_merge['deferred_1Y'] = test_merge['deferred_1Y_x']+test_merge['deferred_1Y_y']\n",
    "test_merge.drop(labels=['deferred_1Y_x', 'deferred_1Y_y'], axis=1, inplace=True)\n",
    "\n",
    "# 2-Years\n",
    "test_merge['deferred_2Y'] = test_merge['deferred_2Y_x']+test_merge['deferred_2Y_y']\n",
    "test_merge.drop(labels=['deferred_2Y_x', 'deferred_2Y_y'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looks like the type ZCC billings are complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the main dataframe as df\n",
    "df = test_merge.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type A No Config Type Billings\n",
    "\n",
    "This file contains type A billings that have a revenue contract start date and end date. We need to map these into the terms of our dataframe.\n",
    "\n",
    "### Steps:\n",
    "1. Rename the columns\n",
    "2. This file has entries for pennies. Need to clear out anything less than $10 in absolute value\n",
    "3. Determine the length of time between start date and end date\n",
    "4. Group this dataframe by currency, period and BU\n",
    "5. Merge this final dataframe with the larger dataframe\n",
    "\n",
    "## NOTE: This file contains two different start date and end date columns. We need to look at all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_excel('../data/Data_2019_P06/type_A_no_config.xlsx', 'DC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.rename(index=str, columns={'Document Currency':'currency', \n",
    "                               'Enterprise Bu':'BU',\n",
    "                               'Invoicing Fiscal Year-Period Desc':'period',\n",
    "                               'Rev Rec Contract End Date Hdr':'end_date_1',\n",
    "                               'Rev Rec Contract End Date Item':'end_date_2',\n",
    "                               'Rev Rec Contract Start Date Hdr': 'start_date_1',\n",
    "                               'Rev Rec Contract Start Date Item': 'start_date_2',\n",
    "                               'Completed Sales Doc Currency':'amount'}, inplace=True)\n",
    "\n",
    "df_A.drop(columns='Product Configtype ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the duplicate dates by taking a max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['start_date_str'] = df_A[['start_date_1','start_date_2']].max(axis=1).astype(int).astype(str)\n",
    "df_A['end_date_str'] = df_A[['end_date_1','end_date_2']].max(axis=1).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['start_date'] = pd.to_datetime(df_A['start_date_str'])\n",
    "df_A['end_date'] = pd.to_datetime(df_A['end_date_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.drop(labels=['end_date_1', 'end_date_2', 'start_date_1', 'start_date_2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['month_interval']=(df_A['end_date']-df_A['start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['months']= (df_A['month_interval']/ np.timedelta64(1,'M')).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I need to map the months into the different integers in my dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rebills = [1, 3, 6, 12, 24, 36]\n",
    "temp_rebill = np.zeros_like(df_A['months'])\n",
    "for i in range(len(df_A)):\n",
    "    temp_rebill[i] = min(list_rebills, key=lambda x:abs(x-df_A['months'][i]))\n",
    "df_A['rebill_months']=temp_rebill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_A['months'], df_A['rebill_months'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the dataframe by rebill_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop what we dont need\n",
    "df_A.drop(columns = ['start_date', 'end_date', 'month_interval', 'months'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['rebill_months'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_A = df_A.groupby(['currency', 'BU', 'period'], as_index=False).sum()\n",
    "# The code above adds the months as well. I do not want this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')\n",
    "temp = df_A.pivot_table('amount', ['currency', 'BU', 'period'], 'rebill_months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.rename(columns = {1.0: 'one_month', 3.0:'three_months',\n",
    "                                 6.0:'six_months', 12.0:'twelve_months',\n",
    "                                 24.0:'two_years', 36.0:'three_years'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I need to combine the new dataframe (df_A) with df\n",
    "df_merged = pd.merge(df, temp, how='outer', \n",
    "                 left_on=['curr', 'BU', 'period'],\n",
    "                right_on=['currency', 'BU', 'period'])\n",
    "df_merged = df_merged.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['deferred_1M'] = df_merged['deferred_1M']+df_merged['one_month']\n",
    "df_merged.drop(labels=['one_month'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['deferred_3M'] = df_merged['deferred_3M']+df_merged['three_months']\n",
    "df_merged.drop(labels=['three_months'], axis=1, inplace=True)\n",
    "\n",
    "df_merged['deferred_6M'] = df_merged['deferred_6M']+df_merged['six_months']\n",
    "df_merged.drop(labels=['six_months'], axis=1, inplace=True)\n",
    "\n",
    "df_merged['deferred_1Y'] = df_merged['deferred_1Y']+df_merged['twelve_months']\n",
    "df_merged.drop(labels=['twelve_months'], axis=1, inplace=True)\n",
    "\n",
    "df_merged['deferred_2Y'] = df_merged['deferred_2Y']+df_merged['two_years']\n",
    "df_merged.drop(labels=['two_years'], axis=1, inplace=True)\n",
    "\n",
    "df_merged['deferred_3Y'] = df_merged['deferred_3Y']+df_merged['three_years']\n",
    "df_merged.drop(labels=['three_years'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['deferred_3M'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map = pd.read_excel('../data/Data_2019_P06/currency_map.xlsx', 'curr_map')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map['Country'] = curr_map['Country'].map(lambda x: str(x)[:-4])\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map.set_index('Country', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Currency']['United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['add_this']= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX_rates = pd.read_excel('../data/Data_2019_P06/FX_data.xlsx', 'to_matlab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i) #JTLWASHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
